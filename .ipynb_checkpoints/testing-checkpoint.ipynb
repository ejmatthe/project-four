{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e7b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "     ------------------------------------ 176.1/176.1 kB 366.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from keras-tuner) (21.3)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from keras-tuner) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ejmat\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.3)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "# Import the modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c6a905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>suicides_no</th>\n",
       "      <th>population</th>\n",
       "      <th>suicides_per_100k_pop</th>\n",
       "      <th>gdp_for_year_USD</th>\n",
       "      <th>gdp_per_capita_USD</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>21</td>\n",
       "      <td>312900</td>\n",
       "      <td>6.71</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>35-54 years</td>\n",
       "      <td>16</td>\n",
       "      <td>308000</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>Silent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>female</td>\n",
       "      <td>15-24 years</td>\n",
       "      <td>14</td>\n",
       "      <td>289700</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>Generation X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>75+ years</td>\n",
       "      <td>1</td>\n",
       "      <td>21800</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>G.I. Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1987</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34 years</td>\n",
       "      <td>9</td>\n",
       "      <td>274300</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.156625e+09</td>\n",
       "      <td>796</td>\n",
       "      <td>Boomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year     sex          age  suicides_no  population  \\\n",
       "0  Albania  1987    male  15-24 years           21      312900   \n",
       "1  Albania  1987    male  35-54 years           16      308000   \n",
       "2  Albania  1987  female  15-24 years           14      289700   \n",
       "3  Albania  1987    male    75+ years            1       21800   \n",
       "4  Albania  1987    male  25-34 years            9      274300   \n",
       "\n",
       "   suicides_per_100k_pop  gdp_for_year_USD  gdp_per_capita_USD  \\\n",
       "0                   6.71      2.156625e+09                 796   \n",
       "1                   5.19      2.156625e+09                 796   \n",
       "2                   4.83      2.156625e+09                 796   \n",
       "3                   4.59      2.156625e+09                 796   \n",
       "4                   3.28      2.156625e+09                 796   \n",
       "\n",
       "        generation  \n",
       "0     Generation X  \n",
       "1           Silent  \n",
       "2     Generation X  \n",
       "3  G.I. Generation  \n",
       "4          Boomers  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the CSV\n",
    "suicides_df = pd.read_csv(\"output/suicides.csv\")\n",
    "\n",
    "suicides_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e35de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suicides_per_100k_pop</th>\n",
       "      <th>gdp_per_capita_USD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.71</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.19</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.83</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.59</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.28</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   suicides_per_100k_pop  gdp_per_capita_USD\n",
       "0                   6.71                 796\n",
       "1                   5.19                 796\n",
       "2                   4.83                 796\n",
       "3                   4.59                 796\n",
       "4                   3.28                 796"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make dataframe to compare suicide rate and GDP per capita\n",
    "suicides_gdp_df = suicides_df[[\"suicides_per_100k_pop\", \"gdp_per_capita_USD\"]]\n",
    "suicides_gdp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725e6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummies\n",
    "country_dummies = pd.get_dummies(suicides_df[\"country\"])\n",
    "sex_dummies = pd.get_dummies(suicides_df[\"sex\"])\n",
    "age_dummies = pd.get_dummies(suicides_df[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5117c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suicides_per_100k_pop</th>\n",
       "      <th>gdp_per_capita_USD</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>Aruba</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Azerbaijan</th>\n",
       "      <th>...</th>\n",
       "      <th>Uruguay</th>\n",
       "      <th>Uzbekistan</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>15-24 years</th>\n",
       "      <th>25-34 years</th>\n",
       "      <th>35-54 years</th>\n",
       "      <th>5-14 years</th>\n",
       "      <th>55-74 years</th>\n",
       "      <th>75+ years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.71</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.19</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.83</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.59</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.28</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   suicides_per_100k_pop  gdp_per_capita_USD  Albania  Antigua and Barbuda  \\\n",
       "0                   6.71                 796        1                    0   \n",
       "1                   5.19                 796        1                    0   \n",
       "2                   4.83                 796        1                    0   \n",
       "3                   4.59                 796        1                    0   \n",
       "4                   3.28                 796        1                    0   \n",
       "\n",
       "   Argentina  Armenia  Aruba  Australia  Austria  Azerbaijan  ...  Uruguay  \\\n",
       "0          0        0      0          0        0           0  ...        0   \n",
       "1          0        0      0          0        0           0  ...        0   \n",
       "2          0        0      0          0        0           0  ...        0   \n",
       "3          0        0      0          0        0           0  ...        0   \n",
       "4          0        0      0          0        0           0  ...        0   \n",
       "\n",
       "   Uzbekistan  female  male  15-24 years  25-34 years  35-54 years  \\\n",
       "0           0       0     1            1            0            0   \n",
       "1           0       0     1            0            0            1   \n",
       "2           0       1     0            1            0            0   \n",
       "3           0       0     1            0            0            0   \n",
       "4           0       0     1            0            1            0   \n",
       "\n",
       "   5-14 years  55-74 years  75+ years  \n",
       "0           0            0          0  \n",
       "1           0            0          0  \n",
       "2           0            0          0  \n",
       "3           0            0          1  \n",
       "4           0            0          0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add dummies\n",
    "suicides_x_df = pd.concat([suicides_gdp_df, country_dummies, sex_dummies, age_dummies], axis=1)\n",
    "suicides_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6729e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and feature sets\n",
    "y = suicides_gdp_df[\"suicides_per_100k_pop\"].values\n",
    "x = suicides_x_df.drop(columns=\"suicides_per_100k_pop\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff220375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654af120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical data for neural network\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "x_scaler = scaler.fit(x_train)\n",
    "\n",
    "# Scale the data\n",
    "x_train_scaled = x_scaler.transform(x_train)\n",
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9388e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=110,\n",
    "        step=2), activation=activation, input_dim=110))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=110,\n",
    "            step=2),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c15d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f040d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 35s]\n",
      "val_accuracy: 0.0723220705986023\n",
      "\n",
      "Best val_accuracy So Far: 0.08598130941390991\n",
      "Total elapsed time: 00h 14m 00s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run the kerastuner search for best hyperparameters\n",
    "tuner.search(x_train_scaled,y_train,epochs=20,validation_data=(x_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8192177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 75,\n",
       " 'num_layers': 2,\n",
       " 'units_0': 35,\n",
       " 'units_1': 21,\n",
       " 'units_2': 21,\n",
       " 'units_3': 19,\n",
       " 'units_4': 83,\n",
       " 'units_5': 5,\n",
       " 'tuner/epochs': 20,\n",
       " 'tuner/initial_epoch': 7,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0051'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best model hyperparameters\n",
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d93d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0054 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 75\n",
      "num_layers: 2\n",
      "units_0: 35\n",
      "units_1: 21\n",
      "units_2: 21\n",
      "units_3: 19\n",
      "units_4: 83\n",
      "units_5: 5\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0051\n",
      "Score: 0.08598130941390991\n",
      "\n",
      "Trial 0046 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 99\n",
      "num_layers: 2\n",
      "units_0: 75\n",
      "units_1: 15\n",
      "units_2: 51\n",
      "units_3: 79\n",
      "units_4: 69\n",
      "units_5: 11\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0042\n",
      "Score: 0.08540618419647217\n",
      "\n",
      "Trial 0055 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 63\n",
      "num_layers: 5\n",
      "units_0: 23\n",
      "units_1: 5\n",
      "units_2: 45\n",
      "units_3: 87\n",
      "units_4: 99\n",
      "units_5: 67\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0049\n",
      "Score: 0.08224298804998398\n",
      "\n",
      "Trial 0016 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 37\n",
      "num_layers: 4\n",
      "units_0: 7\n",
      "units_1: 35\n",
      "units_2: 103\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "units_3: 1\n",
      "tuner/trial_id: 0012\n",
      "units_4: 25\n",
      "units_5: 65\n",
      "Score: 0.0815240815281868\n",
      "\n",
      "Trial 0042 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 99\n",
      "num_layers: 2\n",
      "units_0: 75\n",
      "units_1: 15\n",
      "units_2: 51\n",
      "units_3: 79\n",
      "units_4: 69\n",
      "units_5: 11\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0035\n",
      "Score: 0.07907979935407639\n",
      "\n",
      "Trial 0058 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 89\n",
      "num_layers: 1\n",
      "units_0: 17\n",
      "units_1: 75\n",
      "units_2: 103\n",
      "units_3: 57\n",
      "units_4: 47\n",
      "units_5: 13\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.07749820500612259\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 37\n",
      "num_layers: 4\n",
      "units_0: 7\n",
      "units_1: 35\n",
      "units_2: 103\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "units_3: 1\n",
      "tuner/trial_id: 0001\n",
      "units_4: 25\n",
      "units_5: 65\n",
      "Score: 0.07534147799015045\n",
      "\n",
      "Trial 0059 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 59\n",
      "num_layers: 2\n",
      "units_0: 13\n",
      "units_1: 45\n",
      "units_2: 3\n",
      "units_3: 65\n",
      "units_4: 103\n",
      "units_5: 11\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.0723220705986023\n",
      "\n",
      "Trial 0047 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 73\n",
      "num_layers: 1\n",
      "units_0: 33\n",
      "units_1: 15\n",
      "units_2: 65\n",
      "units_3: 95\n",
      "units_4: 97\n",
      "units_5: 97\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0043\n",
      "Score: 0.07174694538116455\n",
      "\n",
      "Trial 0051 summary\n",
      "Hyperparameters:\n",
      "activation: tanh\n",
      "first_units: 75\n",
      "num_layers: 2\n",
      "units_0: 35\n",
      "units_1: 21\n",
      "units_2: 21\n",
      "units_3: 19\n",
      "units_4: 83\n",
      "units_5: 5\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.06829618662595749\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8740bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 75)                8325      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 35)                2660      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                756       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11763 (45.95 KB)\n",
      "Trainable params: 11763 (45.95 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c066320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model \n",
    "nn_model_tuned = tf.keras.models.Sequential()\n",
    "nn_model_tuned.add(tf.keras.layers.Dense(units=75, activation=\"tanh\", input_dim=110))\n",
    "nn_model_tuned.add(tf.keras.layers.Dense(units=35, activation=\"tanh\"))\n",
    "nn_model_tuned.add(tf.keras.layers.Dense(units=21, activation=\"tanh\"))\n",
    "nn_model_tuned.add(tf.keras.layers.Dense(units=1, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model_tuned.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "552f42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2136 - accuracy: 0.0698\n",
      "Epoch 2/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.0786 - accuracy: 0.0586\n",
      "Epoch 3/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2214 - accuracy: 0.0685\n",
      "Epoch 4/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2108 - accuracy: 0.0661\n",
      "Epoch 5/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2439 - accuracy: 0.0656\n",
      "Epoch 6/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2594 - accuracy: 0.0671\n",
      "Epoch 7/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.3674 - accuracy: 0.0617\n",
      "Epoch 8/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4877 - accuracy: 0.0624\n",
      "Epoch 9/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4904 - accuracy: 0.0636\n",
      "Epoch 10/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5087 - accuracy: 0.0638\n",
      "Epoch 11/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4513 - accuracy: 0.0612\n",
      "Epoch 12/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -182.4943 - accuracy: 0.0639\n",
      "Epoch 13/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -182.4763 - accuracy: 0.0652\n",
      "Epoch 14/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5015 - accuracy: 0.0643\n",
      "Epoch 15/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5051 - accuracy: 0.0648\n",
      "Epoch 16/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4830 - accuracy: 0.0647\n",
      "Epoch 17/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4995 - accuracy: 0.0649\n",
      "Epoch 18/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5009 - accuracy: 0.0653\n",
      "Epoch 19/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4921 - accuracy: 0.0645\n",
      "Epoch 20/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4934 - accuracy: 0.0616\n",
      "Epoch 21/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5127 - accuracy: 0.0660\n",
      "Epoch 22/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5189 - accuracy: 0.0663\n",
      "Epoch 23/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5029 - accuracy: 0.0665\n",
      "Epoch 24/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4838 - accuracy: 0.0632\n",
      "Epoch 25/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4900 - accuracy: 0.0651\n",
      "Epoch 26/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.4229 - accuracy: 0.0574\n",
      "Epoch 27/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5164 - accuracy: 0.0613\n",
      "Epoch 28/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -182.4564 - accuracy: 0.0640\n",
      "Epoch 29/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -182.5243 - accuracy: 0.0660\n",
      "Epoch 30/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5214 - accuracy: 0.0665\n",
      "Epoch 31/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5260 - accuracy: 0.0664\n",
      "Epoch 32/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5252 - accuracy: 0.0666\n",
      "Epoch 33/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5240 - accuracy: 0.0661\n",
      "Epoch 34/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -182.5284 - accuracy: 0.0669\n",
      "Epoch 35/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.5143 - accuracy: 0.0666\n",
      "Epoch 36/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2853 - accuracy: 0.0648\n",
      "Epoch 37/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2632 - accuracy: 0.0681\n",
      "Epoch 38/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2279 - accuracy: 0.0703\n",
      "Epoch 39/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -182.0552 - accuracy: 0.0748\n",
      "Epoch 40/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2295 - accuracy: 0.0749\n",
      "Epoch 41/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2393 - accuracy: 0.0754\n",
      "Epoch 42/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2377 - accuracy: 0.0757\n",
      "Epoch 43/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2256 - accuracy: 0.0753\n",
      "Epoch 44/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.2312 - accuracy: 0.0708\n",
      "Epoch 45/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -182.1994 - accuracy: 0.0765\n",
      "Epoch 46/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -182.2411 - accuracy: 0.0768\n",
      "Epoch 47/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -182.2308 - accuracy: 0.0752\n",
      "Epoch 48/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.2513 - accuracy: 0.0776\n",
      "Epoch 49/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.6570 - accuracy: 0.0788\n",
      "Epoch 50/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.6772 - accuracy: 0.0772\n",
      "Epoch 51/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8103 - accuracy: 0.0725\n",
      "Epoch 52/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8175 - accuracy: 0.0790\n",
      "Epoch 53/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8339 - accuracy: 0.0786\n",
      "Epoch 54/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8416 - accuracy: 0.0782\n",
      "Epoch 55/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7557 - accuracy: 0.0817\n",
      "Epoch 56/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7292 - accuracy: 0.0793\n",
      "Epoch 57/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7342 - accuracy: 0.0811\n",
      "Epoch 58/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7247 - accuracy: 0.0796\n",
      "Epoch 59/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7290 - accuracy: 0.0786\n",
      "Epoch 60/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7283 - accuracy: 0.0802\n",
      "Epoch 61/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7301 - accuracy: 0.0799\n",
      "Epoch 62/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7312 - accuracy: 0.0802\n",
      "Epoch 63/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7306 - accuracy: 0.0805\n",
      "Epoch 64/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7257 - accuracy: 0.0790\n",
      "Epoch 65/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7228 - accuracy: 0.0802\n",
      "Epoch 66/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7333 - accuracy: 0.0801\n",
      "Epoch 67/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7501 - accuracy: 0.0817\n",
      "Epoch 68/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7585 - accuracy: 0.0818\n",
      "Epoch 69/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.7505 - accuracy: 0.0813\n",
      "Epoch 70/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.7561 - accuracy: 0.0821\n",
      "Epoch 71/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.7611 - accuracy: 0.0817\n",
      "Epoch 72/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.6945 - accuracy: 0.0659\n",
      "Epoch 73/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.7249 - accuracy: 0.0755\n",
      "Epoch 74/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7544 - accuracy: 0.0792\n",
      "Epoch 75/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.5978 - accuracy: 0.0792\n",
      "Epoch 76/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.2146 - accuracy: 0.0809\n",
      "Epoch 77/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.0636 - accuracy: 0.0822\n",
      "Epoch 78/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.0959 - accuracy: 0.0617\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 1s 2ms/step - loss: -180.6668 - accuracy: 0.0441\n",
      "Epoch 80/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.7607 - accuracy: 0.0664\n",
      "Epoch 81/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.7946 - accuracy: 0.0762\n",
      "Epoch 82/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7781 - accuracy: 0.0785\n",
      "Epoch 83/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7450 - accuracy: 0.0809\n",
      "Epoch 84/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7703 - accuracy: 0.0821\n",
      "Epoch 85/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8194 - accuracy: 0.0784\n",
      "Epoch 86/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8133 - accuracy: 0.0820\n",
      "Epoch 87/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8356 - accuracy: 0.0822\n",
      "Epoch 88/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8370 - accuracy: 0.0829\n",
      "Epoch 89/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.7757 - accuracy: 0.0846\n",
      "Epoch 90/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8190 - accuracy: 0.0774\n",
      "Epoch 91/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8225 - accuracy: 0.0721\n",
      "Epoch 92/100\n",
      "653/653 [==============================] - 1s 2ms/step - loss: -181.8426 - accuracy: 0.0819\n",
      "Epoch 93/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8497 - accuracy: 0.0844\n",
      "Epoch 94/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8517 - accuracy: 0.0836\n",
      "Epoch 95/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8161 - accuracy: 0.0825\n",
      "Epoch 96/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8304 - accuracy: 0.0834\n",
      "Epoch 97/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8247 - accuracy: 0.0821\n",
      "Epoch 98/100\n",
      "653/653 [==============================] - 2s 2ms/step - loss: -181.8489 - accuracy: 0.0840\n",
      "Epoch 99/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8380 - accuracy: 0.0833\n",
      "Epoch 100/100\n",
      "653/653 [==============================] - 2s 3ms/step - loss: -181.8421 - accuracy: 0.0836\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_tuned = nn_model_tuned.fit(x_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "746dbebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 - 0s - loss: -1.7755e+02 - accuracy: 0.0782 - 317ms/epoch - 1ms/step\n",
      "Loss: -177.55264282226562, Accuracy: 0.07821711152791977\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model_tuned.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
